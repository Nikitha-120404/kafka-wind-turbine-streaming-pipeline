# Kafka Wind Turbine Streaming Pipeline ğŸš€

## ğŸ“Œ Project Overview

This project demonstrates an **end-to-end real-time data engineering pipeline** built using **Apache Kafka** and **TimescaleDB**.

The system simulates IoT wind turbine sensor data, streams it through Kafka, and stores it inside a TimescaleDB time-series database for analytics and aggregation.

This project showcases real-world concepts used in streaming data engineering:

- Real-time data generation
- Message streaming with Kafka
- Reliable consumption with manual offset commits
- Time-series storage using TimescaleDB
- Continuous aggregates for analytics
- Data compression and retention policies

---

## ğŸ—ï¸ Architecture


Wind Turbine Sensor Simulation
â†“
Kafka Producer
â†“
Kafka Broker
â†“
Kafka Consumer
â†“
TimescaleDB
â†“
Continuous Aggregates & Analytics


---

## âš™ï¸ Technologies Used

- Python
- Apache Kafka
- Confluent Kafka Client
- PostgreSQL / TimescaleDB
- SQL

---

## ğŸ“‚ Project Structure


kafka-wind-turbine-streaming-pipeline/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ wind_turbine_sensorlog.py
â”‚ â”œâ”€â”€ kafka_producer.py
â”‚ â”œâ”€â”€ kafka_consumer_check.py
â”‚ â””â”€â”€ kafka_consumer_to_timescaledb.py
â”‚
â”œâ”€â”€ sql/
â”‚ â””â”€â”€ timescaledb_queries.sql
â”‚
â”œâ”€â”€ output/
â”‚ â””â”€â”€ wind_turbine_streamdata.csv
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âœ¨ Key Features

- Simulated IoT wind turbine sensor data generation
- Kafka Producer for real-time message publishing
- Kafka Consumer for message validation
- Streaming ingestion into TimescaleDB
- Manual Kafka offset commit after successful database insert
- TimescaleDB hypertable for time-series optimization
- Continuous aggregate for 5-minute analytics
- Compression policy for storage optimization
- Retention policy for long-term data management

---

## ğŸ“Š Time-Series Database Design

The project uses TimescaleDB features:

- Hypertables for automatic time partitioning
- Continuous aggregates for fast analytics
- Compression policies for older data
- Data retention policies for cleanup

---

## ğŸ“ˆ Sample Output

Streaming data successfully inserted into TimescaleDB:


output/wind_turbine_streamdata.csv


This file contains sample records generated through the Kafka streaming pipeline.

---

## ğŸ¯ Learning Outcomes

Through this project, I gained hands-on experience with:

- Real-time data streaming pipelines
- Kafka producers and consumers
- Message reliability & offset management
- Time-series database modeling
- Streaming analytics design
- End-to-end data pipeline architecture

---

## ğŸ‘©â€ğŸ’» Author

**Nikitha**
